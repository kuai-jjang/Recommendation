{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "class close_words:\n",
    "    def __init__(self,model,w2i,pca=False,n=5):\n",
    "        self.model=model\n",
    "        self.w2i=w2i\n",
    "        self.n=n\n",
    "        self.i2w=dict(zip(w2i.values(),w2i.keys()))\n",
    "        pca = PCA(n_components=2)\n",
    "        self.embeddings=model['embedding_in.weight'] if not pca else torch.tensor(pca.fit_transform(model['embedding_in.weight']))\n",
    "        \n",
    "        \n",
    "    def input_word(self,word):\n",
    "        self.sample_idx=self.w2i[word]\n",
    "        self.sample_vec=self.embeddings[self.sample_idx]\n",
    "    \n",
    "    def sample_word(self):\n",
    "        \n",
    "        self.sample_idx=random.sample(list(self.w2i.values()),1)[0]\n",
    "        self.sampled_word=self.i2w[self.sample_idx]\n",
    "        self.sample_vec=self.embeddings[self.sample_idx]\n",
    "        print('임의의 단어:',self.sampled_word)\n",
    "    \n",
    "    def l2_dist(self):\n",
    "        \n",
    "        self.trial=torch.mul((self.embeddings-self.sample_vec),(self.embeddings-self.sample_vec))\n",
    "        self.trial[self.sample_idx]=100\n",
    "        self.trial=torch.sum(self.trial,dim=1)\n",
    "        #rec=torch.argmax(-self.trial).item()\n",
    "        idexes=torch.argsort(-self.trial, descending=True)[:self.n]\n",
    "        step=1\n",
    "        print(len(self.i2w))\n",
    "        for idx in idexes:\n",
    "            if idx==len(w2i): #unk 제거\n",
    "                continue\n",
    "            print(step,'번째 가까운 단어:',self.i2w[idx.item()])\n",
    "            step+=1\n",
    "                \n",
    "    def cos_sim(self):\n",
    "      \n",
    "        self.trial=torch.div(torch.sum(torch.mul(self.embeddings,self.sample_vec),dim=1),torch.sum(torch.mul(self.embeddings,self.embeddings),dim=1))\n",
    "     \n",
    "        self.trial[self.sample_idx]=-100\n",
    "        idexes=torch.argsort(self.trial, descending=True)[:self.n]\n",
    "        step=1\n",
    "        for idx in idexes:\n",
    "            if idx==len(w2i)+1: #unk 제거\n",
    "                continue\n",
    "            print(step,'번째 가까운 단어:',self.i2w[idx.item()])\n",
    "            step+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 사이즈: torch.Size([28053, 256])\n",
      "사전 사이즈: 41034\n"
     ]
    }
   ],
   "source": [
    "#model=torch.load('./w2v_withoud_ns',map_location='cpu')\n",
    "model=torch.load('./withous_gut_su_haha_epoch_3',map_location='cpu')['state_dict']\n",
    "\n",
    "with open('./preprocessing//vocab_without_josa_gut_su.pickle','rb') as f:\n",
    "    w2i=pickle.load(f)\n",
    "    \n",
    "print('임베딩 사이즈:',model['embedding_in.weight'].shape)  #unk 랑 embedding이 0부터인것을 몰랐음. 0은 버리면 됨\n",
    "print('사전 사이즈:',len(w2i))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 단어: ('여덟', 'Noun')\n",
      "28052\n",
      "1 번째 가까운 단어: ('foreigners', 'Alpha')\n",
      "2 번째 가까운 단어: ('탕', 'Noun')\n",
      "3 번째 가까운 단어: ('빠르게', 'Adjective')\n",
      "4 번째 가까운 단어: ('친절하십니다만', 'Adjective')\n",
      "5 번째 가까운 단어: ('외우기', 'Verb')\n",
      "임의의 단어 ('여덟', 'Noun')\n",
      "1 번째 가까운 단어: ('빡치는건', 'Adjective')\n",
      "2 번째 가까운 단어: ('아는데', 'Verb')\n",
      "3 번째 가까운 단어: ('더욱이', 'Noun')\n",
      "4 번째 가까운 단어: ('보나', 'Noun')\n",
      "5 번째 가까운 단어: ('즐겁지만', 'Adjective')\n"
     ]
    }
   ],
   "source": [
    "showing=close_words(model,w2i,pca=True)\n",
    "showing.sample_word()\n",
    "showing.l2_dist()\n",
    "print('임의의 단어',showing.sampled_word)\n",
    "showing.cos_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28052\n",
      "1 번째 가까운 단어: ('메데이아', 'Noun')\n",
      "2 번째 가까운 단어: ('충분해서', 'Adjective')\n",
      "3 번째 가까운 단어: ('떨어지는게', 'Verb')\n",
      "4 번째 가까운 단어: ('비제', 'Noun')\n",
      "5 번째 가까운 단어: ('편할듯', 'Adjective')\n",
      "1 번째 가까운 단어: ('들으시기', 'Verb')\n",
      "2 번째 가까운 단어: ('빡치는건', 'Adjective')\n",
      "3 번째 가까운 단어: ('황금', 'Noun')\n",
      "4 번째 가까운 단어: ('싫으', 'Adjective')\n",
      "5 번째 가까운 단어: ('쿼터', 'Noun')\n"
     ]
    }
   ],
   "source": [
    "showing.input_word(('버스','Noun'))\n",
    "showing.l2_dist()\n",
    "showing.cos_sim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNK 빈도수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014246669941204219\n"
     ]
    }
   ],
   "source": [
    "with open('./preprocessing/vocab_without_josa_gut_su_freq.pickle','rb') as f:\n",
    "    total_freq=pickle.load(f)\n",
    "    \n",
    "with open('./preprocessing/vocab_without_josa_gut_su.pickle','rb') as h:\n",
    "    voc=pickle.load(h)\n",
    "    \n",
    "not_unk=list(voc.keys())\n",
    "\n",
    "freq_sum=0\n",
    "\n",
    "def summing(x):\n",
    "    \n",
    "    global freq_sum\n",
    "    freq_sum+=x\n",
    "\n",
    "_=list(map(lambda x:summing(total_freq[x]),not_unk))\n",
    "\n",
    "ratio=(sum(total_freq.values())-freq_sum)/sum(total_freq.values())\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## unk 빈도수가 문제는 아닌듯??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
