{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "\n",
    "class close_words:\n",
    "    def __init__(self,model,w2i,n=5):\n",
    "        self.model=model\n",
    "        self.w2i=w2i\n",
    "        self.n=n\n",
    "        self.i2w=dict(zip(w2i.values(),w2i.keys()))\n",
    "        self.embeddings=model['embedding.weight']\n",
    "    \n",
    "    def sample_word(self):\n",
    "        \n",
    "        self.sample_idx=random.sample(list(self.w2i.values()),1)[0]\n",
    "        self.sampled_word=i2w[self.sample_idx]\n",
    "        self.sample_vec=embeddings[self.sample_idx]\n",
    "        print('임의의 단어:',self.sampled_word)\n",
    "    \n",
    "    def l2_dist(self):\n",
    "        \n",
    "        self.trial=torch.mul((self.embeddings-self.sample_vec),(self.embeddings-self.sample_vec))\n",
    "        self.trial[self.sample_idx]=100\n",
    "        self.trial=torch.sum(self.trial,dim=1)\n",
    "        #rec=torch.argmax(-self.trial).item()\n",
    "        idexes=torch.argsort(-self.trial, descending=True)[:self.n]\n",
    "        for i,idx in enumerate(idexes):\n",
    "            print(i+1,'번째 가까운 단어:',self.i2w[idx.item()])\n",
    "                \n",
    "    def cos_sim(self):\n",
    "      \n",
    "        self.trial=torch.div(torch.sum(torch.mul(self.embeddings,self.sample_vec),dim=1),torch.sum(torch.mul(self.embeddings,self.embeddings),dim=1))\n",
    "     \n",
    "        self.trial[self.sample_idx]=-100\n",
    "        idexes=torch.argsort(self.trial, descending=True)[:self.n]\n",
    "        for i,idx in enumerate(idexes):\n",
    "            print(i+1,'번째 가까운 단어:',self.i2w[idx.item()])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임베딩 사이즈: torch.Size([28103, 256])\n",
      "사전 사이즈: 28101\n"
     ]
    }
   ],
   "source": [
    "model=torch.load('./w2v_withoud_ns',map_location='cpu')\n",
    "\n",
    "with open('./preprocessing//without_josa_etc','rb') as f:\n",
    "    w2i=pickle.load(f)\n",
    "    \n",
    "print('임베딩 사이즈:',model['embedding.weight'].shape)  #unk 랑 embedding이 0부터인것을 몰랐음. 0은 버리면 됨\n",
    "print('사전 사이즈:',len(w2i))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "showing=close_words(model,w2i)\n",
    "showing.sample_word()\n",
    "showing.l2_dist()\n",
    "showing.sample_word()\n",
    "showing.l2_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('./w2v_withoud_ns_epoch_3',map_location='cpu')\n",
    "showing=close_words(model,w2i)\n",
    "showing.sample_word()\n",
    "showing.l2_dist()\n",
    "print('임의의 단어',showing.sampled_word)\n",
    "showing.cos_sim()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
